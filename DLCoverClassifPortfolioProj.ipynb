{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1l4z_kODbv-BFAWHN47y-YkvgKLUJWCPm",
      "authorship_tag": "ABX9TyPg2CqHhahVHwhTpD95lmTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BD-David1108/AI_Projects/blob/main/DLCoverClassifPortfolioProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Greetings! This deep learning project is my final output for Codecademy's final portfolio project for the Deep Learning Fundamentals Aspire Journey from Skillsoft's Codecademy.**\n",
        "\n"
      ],
      "metadata": {
        "id": "Kmx8gzmPSvbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Description**:\n",
        "In this project, I will use deep learning to predict forest cover type (the most common kind of tree cover) based only on cartographic variables. The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. The covertypes are the following:\n",
        "\n",
        "\n",
        "- Spruce/Fir\n",
        "- Lodgepole Pine\n",
        "- Ponderosa Pine\n",
        "- Cottonwood/Willow\n",
        "- Aspen\n",
        "- Douglas-fir\n",
        "- Krummholz\n",
        "\n",
        "\n",
        "Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is raw and has not been scaled or preprocessed. It contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.\n",
        "\n",
        "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so existing forest cover types are mainly a result of ecological processes rather than forest management practices."
      ],
      "metadata": {
        "id": "0Uq8_enrTDNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Objectives**:\n",
        "- Develop one or more classifiers for this multi-class classification problem.\n",
        "- Use TensorFlow with Keras to build classifier(s).\n",
        "- Use knowledge of hyperparameter tuning to improve the performance of the model(s).\n",
        "- Test and analyze performance.\n",
        "- Create clean and modular code."
      ],
      "metadata": {
        "id": "PnuIkt-FTtjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "eGce3277XQ4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, InputLayer, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import pearsonr\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "Olmc58ZEXHh6"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygZ_UY4YUSZ",
        "outputId": "461354b6-a429-447a-c3f2-8c2d53d7b5bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing and inspecting data\n",
        "data = pd.read_csv('/content/drive/MyDrive/data/cover_data.csv')\n",
        "dataset = pd.DataFrame(data)\n",
        "print(dataset.head())\n",
        "print(dataset.shape)\n",
        "print(dataset.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfKC6ZT9XWsx",
        "outputId": "efbed5d0-07d0-4fe7-8fe2-50dbaf211b85"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
            "0       2596      51      3                               258   \n",
            "1       2590      56      2                               212   \n",
            "2       2804     139      9                               268   \n",
            "3       2785     155     18                               242   \n",
            "4       2595      45      2                               153   \n",
            "\n",
            "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
            "0                               0                              510   \n",
            "1                              -6                              390   \n",
            "2                              65                             3180   \n",
            "3                             118                             3090   \n",
            "4                              -1                              391   \n",
            "\n",
            "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
            "0            221             232            148   \n",
            "1            220             235            151   \n",
            "2            234             238            135   \n",
            "3            238             238            122   \n",
            "4            220             234            150   \n",
            "\n",
            "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
            "0                                6279  ...            0            0   \n",
            "1                                6225  ...            0            0   \n",
            "2                                6121  ...            0            0   \n",
            "3                                6211  ...            0            0   \n",
            "4                                6172  ...            0            0   \n",
            "\n",
            "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
            "0            0            0            0            0            0   \n",
            "1            0            0            0            0            0   \n",
            "2            0            0            0            0            0   \n",
            "3            0            0            0            0            0   \n",
            "4            0            0            0            0            0   \n",
            "\n",
            "   Soil_Type39  Soil_Type40  class  \n",
            "0            0            0      5  \n",
            "1            0            0      5  \n",
            "2            0            0      2  \n",
            "3            0            0      2  \n",
            "4            0            0      5  \n",
            "\n",
            "[5 rows x 55 columns]\n",
            "(581012, 55)\n",
            "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
            "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
            "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
            "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
            "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
            "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
            "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
            "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
            "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
            "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
            "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
            "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
            "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
            "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
            "       'Soil_Type39', 'Soil_Type40', 'class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info())\n",
        "print('Classes and number of values in the dataset',Counter(dataset['class']))"
      ],
      "metadata": {
        "id": "5BH9d5Zz4sz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.describe())"
      ],
      "metadata": {
        "id": "LpQzfVY84s7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon inspecting the dataset, we notice that our features contain binary and numerical continuous data that needs to be scaled."
      ],
      "metadata": {
        "id": "FXyqY3hPH7i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset.iloc[:, -1]\n",
        "x = dataset.iloc[:, 0:-2]\n",
        "print(y.shape)\n",
        "print(y.describe())\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x7rxosmK25H",
        "outputId": "dc4ceee2-33f3-449f-8071-bd7378fa813a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581012,)\n",
            "count    581012.000000\n",
            "mean          2.051471\n",
            "std           1.396504\n",
            "min           1.000000\n",
            "25%           1.000000\n",
            "50%           2.000000\n",
            "75%           2.000000\n",
            "max           7.000000\n",
            "Name: class, dtype: float64\n",
            "(581012, 53)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.get_dummies(x)\n",
        "#y = pd.get_dummies(y)\n",
        "#y = pd.DataFrame(y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=.33, random_state=21)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CtPducehseoe"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer([('numeric', Normalizer(),['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
        "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
        "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
        "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
        "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4'])])\n",
        "X_train = ct.fit_transform(X_train)\n",
        "X_test = ct.transform(X_test)\n",
        "X_val = ct.transform(X_val)"
      ],
      "metadata": {
        "id": "43sDvkYM9bbp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing labels for classification\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)\n",
        "Y_val = to_categorical(Y_val)"
      ],
      "metadata": {
        "id": "z_rKDlvy2jLF"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_val.shape)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVZSCP42gtjm",
        "outputId": "319cbbe5-730d-4883-9313-80a748ec31de"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(77856, 8)\n",
            "(311422, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building The Classification Model"
      ],
      "metadata": {
        "id": "qiTm0b5K-p5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "itK7TQF2ZkYY"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(InputLayer(input_shape=(X_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "# Optimizer and Compile\n",
        "opt = Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', 'precision', 'recall', 'f1'])\n",
        "\n",
        "# Additional Optimizations\n",
        "#lr_schedule = LearningRateScheduler(lambda epoch, lr: lr * 0.95)  # Learning rate scheduler\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the Model\n",
        "my_model = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_data=(X_val, Y_val), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWd_Bb65dcE5",
        "outputId": "ef963851-5f06-4090-fed2-1b306c7eda47"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9732/9732 [==============================] - 46s 5ms/step - loss: 0.8459 - accuracy: 0.6397 - val_loss: 0.7358 - val_accuracy: 0.6992\n",
            "Epoch 2/50\n",
            "9732/9732 [==============================] - 43s 4ms/step - loss: 0.8050 - accuracy: 0.6544 - val_loss: 0.7487 - val_accuracy: 0.6793\n",
            "Epoch 3/50\n",
            "9732/9732 [==============================] - 48s 5ms/step - loss: 0.7942 - accuracy: 0.6583 - val_loss: 0.7219 - val_accuracy: 0.6951\n",
            "Epoch 4/50\n",
            "9732/9732 [==============================] - 51s 5ms/step - loss: 0.7833 - accuracy: 0.6618 - val_loss: 0.6985 - val_accuracy: 0.7049\n",
            "Epoch 5/50\n",
            "9732/9732 [==============================] - 59s 6ms/step - loss: 0.7810 - accuracy: 0.6626 - val_loss: 0.7706 - val_accuracy: 0.6719\n",
            "Epoch 6/50\n",
            "9732/9732 [==============================] - 47s 5ms/step - loss: 0.7771 - accuracy: 0.6652 - val_loss: 0.6895 - val_accuracy: 0.7000\n",
            "Epoch 7/50\n",
            "9732/9732 [==============================] - 51s 5ms/step - loss: 0.7773 - accuracy: 0.6654 - val_loss: 0.6798 - val_accuracy: 0.7074\n",
            "Epoch 8/50\n",
            "9732/9732 [==============================] - 41s 4ms/step - loss: 0.7737 - accuracy: 0.6675 - val_loss: 0.6743 - val_accuracy: 0.7185\n",
            "Epoch 9/50\n",
            "9732/9732 [==============================] - 38s 4ms/step - loss: 0.7743 - accuracy: 0.6662 - val_loss: 0.7187 - val_accuracy: 0.6811\n",
            "Epoch 10/50\n",
            "9732/9732 [==============================] - 38s 4ms/step - loss: 0.7688 - accuracy: 0.6690 - val_loss: 0.6872 - val_accuracy: 0.7109\n",
            "Epoch 11/50\n",
            "9732/9732 [==============================] - 38s 4ms/step - loss: 0.7659 - accuracy: 0.6704 - val_loss: 0.6812 - val_accuracy: 0.7166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "y_estimate = model.predict(X_test, verbose=0)\n",
        "y_estimate = np.argmax(y_estimate, axis=1)\n",
        "y_true = np.argmax(Y_test, axis=1)\n",
        "print(classification_report(y_true, y_estimate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWYDikwWPZgB",
        "outputId": "5839b654-0bd9-46c3-fde6-603daaae1b7c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5992/5992 [==============================] - 15s 2ms/step - loss: 0.6738 - accuracy: 0.7192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      0.67      0.70     69974\n",
            "           2       0.73      0.85      0.78     93580\n",
            "           3       0.61      0.80      0.69     11742\n",
            "           4       0.29      0.38      0.33       879\n",
            "           5       1.00      0.00      0.00      3027\n",
            "           6       0.00      0.00      0.00      5688\n",
            "           7       0.83      0.32      0.46      6844\n",
            "\n",
            "    accuracy                           0.72    191734\n",
            "   macro avg       0.60      0.43      0.42    191734\n",
            "weighted avg       0.71      0.72      0.70    191734\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "predictions = model.predict(X_test)\n",
        "predictions_binary = (predictions > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of3cGiyrkUng",
        "outputId": "c02df7bb-3928-4997-c18d-b36a157581bd"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5992/5992 [==============================] - 10s 2ms/step\n"
          ]
        }
      ]
    }
  ]
}